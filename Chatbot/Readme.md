# My chatbot
used Sea2Seq Model
A chat bot Seq2Seq model consists of an encoder and a decoder. During training, it learns to map input text to output text by minimizing the difference between the predicted output and actual output. Once trained, it can generate responses to input text by passing the input through the encoder and using the resulting vector as input to the decoder. It's a powerful technique for developing chatbots that can understand and generate natural language responses.
